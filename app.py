# app.py

import os
import streamlit as st
import glob

from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser

from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

FAISS_INDEX_PATH = "faiss_index"


@st.cache_resource
def load_and_build_db():
    print("VeritabanÄ± kontrol ediliyor ve yÃ¼kleniyor...")

    model_name = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
    embeddings = HuggingFaceEmbeddings(model_name=model_name)

    if os.path.exists(FAISS_INDEX_PATH):
        print("Mevcut veritabanÄ± bulundu, yÃ¼kleniyor.")
        db = FAISS.load_local(FAISS_INDEX_PATH, embeddings, allow_dangerous_deserialization=True)
    else:
        print("VeritabanÄ± bulunamadÄ±, PDF'lerden oluÅŸturuluyor...")
        pdf_files = glob.glob("data/*.pdf")
        if not pdf_files:
            st.error("HATA: 'data' klasÃ¶rÃ¼nde okunacak PDF dosyasÄ± bulunamadÄ±.")
            st.stop()

        all_documents = []
        for pdf_path in pdf_files:
            loader = PyPDFLoader(pdf_path)
            documents = loader.load()
            all_documents.extend(documents)

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        docs = text_splitter.split_documents(all_documents)

        db = FAISS.from_documents(docs, embeddings)
        db.save_local(FAISS_INDEX_PATH)
        print("VeritabanÄ± oluÅŸturuldu ve kaydedildi.")

    # --- DEÄÄ°ÅÄ°KLÄ°K BURADA ---
    # Daha fazla baÄŸlam saÄŸlamak iÃ§in getirilecek parÃ§a sayÄ±sÄ±nÄ± artÄ±rÄ±yoruz.
    retriever = db.as_retriever(search_kwargs={'k': 5})
    # -------------------------

    llm = ChatGoogleGenerativeAI(model="gemini-pro-latest", temperature=0.1, convert_system_message_to_human=True)

    print("Modeller ve veritabanÄ± baÅŸarÄ±yla hazÄ±rlandÄ±.")
    return retriever, llm


def create_rag_chain(retriever, llm):
    template = """
    ### TALÄ°MAT:
    Sana verilen `BAÄLAM` bÃ¶lÃ¼mÃ¼ndeki bilgileri kullanarak `SORU` bÃ¶lÃ¼mÃ¼ndeki soruyu yanÄ±tla. CevabÄ±n dÄ±ÅŸarÄ±dan bilgi iÃ§ermemelidir. EÄŸer baÄŸlamda sorunun cevabÄ± yoksa, 'Bu konuda saÄŸlanan dokÃ¼manda bir bilgi bulamadÄ±m.' de. CevaplarÄ±nÄ± TÃ¼rkÃ§e ve anlaÅŸÄ±lÄ±r bir dille yaz.

    ### BAÄLAM:
    {context}

    ### SORU:
    {question}

    ### CEVAP:
    """
    prompt = PromptTemplate(template=template, input_variables=["context", "question"])
    return {"context": retriever, "question": RunnablePassthrough()} | prompt | llm | StrOutputParser()


# --- Ana Streamlit UygulamasÄ± ---
st.set_page_config(page_title="Kurumsal SÃ¼rdÃ¼rÃ¼lebilirlik AsistanÄ±", layout="wide")
st.title("ğŸŒ± Kurumsal SÃ¼rdÃ¼rÃ¼lebilirlik AsistanÄ±")
st.write(
    "Bu asistan, Borsa Ä°stanbul SÃ¼rdÃ¼rÃ¼lebilirlik Rehberi ve Erdem & Erdem Ã‡SY SÃ¶zlÃ¼ÄŸÃ¼'ndeki bilgileri kullanarak sorularÄ±nÄ±zÄ± yanÄ±tlar.")

st.markdown("""
**Ã–rnek Sorular:**
- YeÅŸil aklama (greenwashing) nedir?
- Bir sÃ¼rdÃ¼rÃ¼lebilirlik stratejisi nasÄ±l hazÄ±rlanÄ±r?
- TSRS nedir?
- Ä°klimle ilgili fiziksel riskler nelerdir?
""")
st.markdown("---")

if 'GOOGLE_API_KEY' not in st.secrets:
    st.error("HATA: GOOGLE_API_KEY bulunamadÄ±. LÃ¼tfen Streamlit Cloud ayarlarÄ±ndan 'Secrets' bÃ¶lÃ¼mÃ¼ne ekleyin.")
    st.stop()

try:
    retriever, llm = load_and_build_db()
    rag_chain = create_rag_chain(retriever, llm)
except Exception as e:
    st.error(f"BaÅŸlangÄ±Ã§ sÄ±rasÄ±nda bir hata oluÅŸtu: {e}")
    st.stop()

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("SÃ¼rdÃ¼rÃ¼lebilirlik stratejisi, raporlama veya bir terim hakkÄ±nda soru sorun..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("DÃ¼ÅŸÃ¼nÃ¼yorum..."):
            response = rag_chain.invoke(prompt)
            st.markdown(response)

    st.session_state.messages.append({"role": "assistant", "content": response})

st.markdown("---")
st.caption(
    "Bu asistanÄ±n bilgi tabanÄ±, Borsa Ä°stanbul SÃ¼rdÃ¼rÃ¼lebilirlik Rehberi ve Erdem & Erdem Ã‡SY Terimler SÃ¶zlÃ¼ÄŸÃ¼ dokÃ¼manlarÄ±ndan oluÅŸturulmuÅŸtur.")